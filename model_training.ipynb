{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
        "from resnet import resnet18_bottleneck, resnet34_bottleneck, resnet50_bottleneck, resnet101_bottleneck, resnet152_bottleneck\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "metadata": {
        "id": "hIia8Ncl1N2S"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling resnets on GPU - Training and Data Loading"
      ],
      "metadata": {
        "id": "wlGUSVv01Rtq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pnxbAZMH0B_u"
      },
      "outputs": [],
      "source": [
        "path = \"./data\"\n",
        "workers = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lr = 0.0001\n",
        "epochs = 100\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "    root=path, train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=True, num_workers=workers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISoSluSv9g9P",
        "outputId": "205ca98a-5050-45fc-b323-c535509149f1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader_enum = enumerate(trainloader)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"data_load\"):\n",
        "        batch_idx, (inputs, targets) = next(trainloader_enum)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)       \n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVN1XkmnADTG",
        "outputId": "5b68c7e9-411d-4ed0-e33b-8b3542b9b97c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              data_load         0.62%     489.000us        99.95%      78.892ms      78.892ms       0.000us         0.00%      68.000us      68.000us             1  \n",
            "                                               aten::to         6.20%       4.891ms        13.66%      10.778ms       1.796ms       0.000us         0.00%      68.000us      11.333us             6  \n",
            "                                         aten::_to_copy         0.05%      43.000us         7.46%       5.887ms       2.943ms       0.000us         0.00%      68.000us      34.000us             2  \n",
            "                                            aten::copy_         0.06%      45.000us         7.28%       5.749ms       2.874ms      68.000us       100.00%      68.000us      34.000us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      68.000us       100.00%      68.000us      34.000us             2  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        85.56%      67.533ms        85.68%      67.627ms      67.627ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                            aten::empty         0.05%      39.000us         0.05%      39.000us       9.750us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                          aten::detach_         0.02%      16.000us         0.04%      29.000us       7.250us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                                detach_         0.02%      13.000us         0.02%      13.000us       3.250us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                             aten::set_         0.03%      24.000us         0.03%      24.000us       6.000us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                                    aten::empty_strided         0.12%      95.000us         0.12%      95.000us      47.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                        cudaMemcpyAsync         7.13%       5.629ms         7.13%       5.629ms       2.814ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                  cudaStreamSynchronize         0.10%      75.000us         0.10%      75.000us      37.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                  cudaDeviceSynchronize         0.05%      37.000us         0.05%      37.000us      37.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 78.929ms\n",
            "Self CUDA time total: 68.000us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = resnet50_bottleneck(large_mode=True)\n",
        "net = net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[40,80], gamma=0.1)"
      ],
      "metadata": {
        "id": "ELBjLDws-gsb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.perf_counter()\n",
        "\n",
        "# Train\n",
        "for epoch in range(0, epochs):\n",
        "    net.train()\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        del inputs, labels\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f'Average loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "stop = time.perf_counter()\n",
        "\n",
        "print(f'Total training time: {stop-start}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO-MjM5I7rGB",
        "outputId": "bc0d7ad5-dac7-4d52-9396-3fb541088a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Average loss: 4.602475605010986\n",
            "Average loss: 4.5941401290893555\n",
            "Average loss: 4.592751932144165\n",
            "Average loss: 4.59194890499115\n",
            "Average loss: 4.588705639839173\n",
            "Average loss: 4.584306879043579\n",
            "Average loss: 4.581297531127929\n",
            "\n",
            "Epoch: 1\n",
            "Average loss: 4.5835423040390015\n",
            "Average loss: 4.587651910781861\n",
            "Average loss: 4.580157947540283\n",
            "Average loss: 4.57881489276886\n",
            "Average loss: 4.582628808021545\n",
            "Average loss: 4.576735816001892\n",
            "Average loss: 4.572474827766419\n",
            "\n",
            "Epoch: 2\n",
            "Average loss: 4.573218035697937\n",
            "Average loss: 4.56801595211029\n",
            "Average loss: 4.5822995042800905\n",
            "Average loss: 4.585709176063538\n",
            "Average loss: 4.577975063323975\n",
            "Average loss: 4.575355472564698\n",
            "Average loss: 4.570017056465149\n",
            "\n",
            "Epoch: 3\n",
            "Average loss: 4.575529613494873\n",
            "Average loss: 4.573502645492554\n",
            "Average loss: 4.572918243408203\n",
            "Average loss: 4.571292500495911\n",
            "Average loss: 4.564483857154846\n",
            "Average loss: 4.562680125236511\n",
            "Average loss: 4.569099345207214\n",
            "\n",
            "Epoch: 4\n",
            "Average loss: 4.56195634841919\n",
            "Average loss: 4.568769483566284\n",
            "Average loss: 4.56394172668457\n",
            "Average loss: 4.561760349273682\n",
            "Average loss: 4.571761293411255\n",
            "Average loss: 4.565498824119568\n",
            "Average loss: 4.55791419506073\n"
          ]
        }
      ]
    }
  ]
}