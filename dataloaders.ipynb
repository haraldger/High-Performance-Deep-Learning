{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling memory loading\n",
        "Another crucial part of training a deep learning model is the dataset, and of course loading the dataset from disk. This task can be parallelized, and we will now investigate how the number of CPU loaders affect the time."
      ],
      "metadata": {
        "id": "uDb9BLWu4uW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "outputs": [],
      "metadata": {
        "id": "W73hMEoHNw_s"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./data\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64"
      ],
      "outputs": [],
      "metadata": {
        "id": "itpSTtyAeR8B"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "    root=path, train=True, download=True, transform=transform_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxzlIGeEePat",
        "outputId": "b2545e31-9380-41e9-ff3a-f574625694d8"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset, num_workers, sort_string):\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    trainloader_enum = enumerate(trainloader)\n",
        "\n",
        "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "        with record_function(\"data_load\"):\n",
        "            batch_idx, (inputs, targets) = next(trainloader_enum)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)       \n",
        "\n",
        "    print(prof.key_averages().table(sort_by=sort_string, row_limit=15))"
      ],
      "outputs": [],
      "metadata": {
        "id": "kk387JXbeNug"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1 Loader"
      ],
      "metadata": {
        "id": "yxwpniRs5qGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 1\n",
        "sort_string = \"cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              data_load         0.08%       4.334ms        99.97%        5.366s        5.366s       0.000us         0.00%      72.000us      72.000us             1  \n",
            "                                               aten::to         0.00%      72.000us        99.46%        5.338s        1.335s       0.000us         0.00%      72.000us      18.000us             4  \n",
            "                                         aten::_to_copy         0.00%      85.000us        99.46%        5.338s        2.669s       0.000us         0.00%      72.000us      36.000us             2  \n",
            "                                            aten::copy_         0.00%      95.000us        94.58%        5.077s        2.538s      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                                            aten::zeros         0.03%       1.586ms         0.03%       1.599ms     799.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                            aten::empty         0.00%      37.000us         0.00%      37.000us       6.167us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::zero_         0.00%       2.000us         0.00%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.43%      22.841ms         0.43%      22.928ms      22.928ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                             aten::lift         0.00%      14.000us         0.00%      14.000us       7.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                          aten::detach_         0.00%      11.000us         0.00%      14.000us       7.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                                detach_         0.00%       3.000us         0.00%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                             aten::set_         0.00%      34.000us         0.00%      34.000us      17.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                     cudaGetDeviceCount         0.00%       2.000us         0.00%       2.000us       2.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                cudaGetDeviceProperties         0.00%     195.000us         0.00%     195.000us     195.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.367s\n",
            "Self CUDA time total: 72.000us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LPzBLow4n4_",
        "outputId": "8e3ebf5e-bea4-4979-f947-9c1a7d4e69f4"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2 loaders"
      ],
      "metadata": {
        "id": "Rpx95fIMAzut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 2\n",
        "sort_string = \"self_cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::copy_         0.09%      38.000us         8.80%       3.587ms       1.794ms      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                                            aten::zeros         0.13%      51.000us         0.16%      65.000us      32.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                            aten::empty         0.07%      27.000us         0.07%      27.000us       4.500us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::zero_         0.01%       3.000us         0.01%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                              data_load         0.48%     196.000us        99.82%      40.706ms      40.706ms       0.000us         0.00%      72.000us      72.000us             1  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        88.57%      36.118ms        88.65%      36.150ms      36.150ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                               aten::to         1.61%     657.000us        10.63%       4.333ms       1.083ms       0.000us         0.00%      72.000us      18.000us             4  \n",
            "                                             aten::lift         0.01%       5.000us         0.01%       5.000us       2.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                          aten::detach_         0.01%       3.000us         0.01%       6.000us       3.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                                detach_         0.01%       3.000us         0.01%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                             aten::set_         0.02%       9.000us         0.02%       9.000us       4.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                         aten::_to_copy         0.06%      25.000us         9.01%       3.676ms       1.838ms       0.000us         0.00%      72.000us      36.000us             2  \n",
            "                                    aten::empty_strided         0.16%      64.000us         0.16%      64.000us      32.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                        cudaMemcpyAsync         8.50%       3.467ms         8.50%       3.467ms       1.734ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 40.779ms\n",
            "Self CUDA time total: 72.000us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "ENAVnl-VAzuu",
        "outputId": "fad112b4-0ad5-4419-ad0d-4f2b9bf95f77"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4 loaders"
      ],
      "metadata": {
        "id": "SDmijYcAAzuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 4\n",
        "sort_string = \"self_cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::copy_         0.17%      49.000us        16.54%       4.708ms       2.354ms      75.000us       100.00%      75.000us      37.500us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      75.000us       100.00%      75.000us      37.500us             2  \n",
            "                                            aten::zeros         0.20%      56.000us         0.23%      66.000us      33.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                            aten::empty         0.09%      26.000us         0.09%      26.000us       4.333us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::zero_         0.01%       2.000us         0.01%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                              data_load         0.87%     249.000us        99.68%      28.371ms      28.371ms       0.000us         0.00%      75.000us      75.000us             1  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        79.21%      22.543ms        79.35%      22.583ms      22.583ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                               aten::to         2.38%     678.000us        19.38%       5.516ms       1.379ms       0.000us         0.00%      75.000us      18.750us             4  \n",
            "                                             aten::lift         0.01%       4.000us         0.01%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                          aten::detach_         0.03%       8.000us         0.04%      11.000us       5.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                                detach_         0.01%       3.000us         0.01%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                             aten::set_         0.04%      11.000us         0.04%      11.000us       5.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                         aten::_to_copy         0.12%      35.000us        17.00%       4.838ms       2.419ms       0.000us         0.00%      75.000us      37.500us             2  \n",
            "                                    aten::empty_strided         0.33%      95.000us         0.33%      95.000us      47.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                        cudaMemcpyAsync        16.07%       4.575ms        16.07%       4.575ms       2.288ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 28.461ms\n",
            "Self CUDA time total: 75.000us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "_c9EE4TPAzuv",
        "outputId": "47329068-e028-4b05-e1ca-3df88c907cb8"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8 loaders"
      ],
      "metadata": {
        "id": "fjC4BrAuAzuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 8\n",
        "sort_string = \"cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              data_load         1.67%     253.000us        99.52%      15.049ms      15.049ms       0.000us         0.00%      71.000us      71.000us             1  \n",
            "                                               aten::to        10.51%       1.589ms        35.33%       5.342ms       1.335ms       0.000us         0.00%      71.000us      17.750us             4  \n",
            "                                         aten::_to_copy         0.24%      37.000us        24.82%       3.753ms       1.877ms       0.000us         0.00%      71.000us      35.500us             2  \n",
            "                                            aten::copy_         0.29%      44.000us        23.94%       3.620ms       1.810ms      71.000us       100.00%      71.000us      35.500us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      71.000us       100.00%      71.000us      35.500us             2  \n",
            "                                            aten::zeros         0.50%      76.000us         0.58%      87.000us      43.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                            aten::empty         0.19%      28.000us         0.19%      28.000us       4.667us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::zero_         0.02%       3.000us         0.02%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        61.92%       9.363ms        62.17%       9.400ms       9.400ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                             aten::lift         0.03%       5.000us         0.03%       5.000us       2.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                          aten::detach_         0.06%       9.000us         0.07%      11.000us       5.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                                detach_         0.01%       2.000us         0.01%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                             aten::set_         0.06%       9.000us         0.06%       9.000us       4.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                    aten::empty_strided         0.63%      96.000us         0.63%      96.000us      48.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                        cudaMemcpyAsync        23.11%       3.494ms        23.11%       3.494ms       1.747ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 15.121ms\n",
            "Self CUDA time total: 71.000us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "pu6Lo8HsAzuw",
        "outputId": "9a71bff5-987e-4c42-feaa-091d72f39baa"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16 loaders"
      ],
      "metadata": {
        "id": "1gxVnQ_hAzuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 16\n",
        "sort_string = \"cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              data_load        10.83%       5.393ms        99.88%      49.758ms      49.758ms       0.000us         0.00%      72.000us      72.000us             1  \n",
            "                                               aten::to         3.07%       1.529ms         7.86%       3.917ms     979.250us       0.000us         0.00%      72.000us      18.000us             4  \n",
            "                                         aten::_to_copy         0.05%      26.000us         4.79%       2.388ms       1.194ms       0.000us         0.00%      72.000us      36.000us             2  \n",
            "                                            aten::copy_         0.09%      44.000us         4.56%       2.273ms       1.137ms      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      72.000us       100.00%      72.000us      36.000us             2  \n",
            "                                            aten::zeros         0.18%      88.000us         0.20%     101.000us      50.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                            aten::empty         0.06%      31.000us         0.06%      31.000us       5.167us       0.000us         0.00%       0.000us       0.000us             6  \n",
            "                                            aten::zero_         0.01%       3.000us         0.01%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        80.99%      40.346ms        81.07%      40.386ms      40.386ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                                             aten::lift         0.01%       5.000us         0.01%       5.000us       2.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                          aten::detach_         0.01%       6.000us         0.02%       9.000us       4.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                                detach_         0.01%       3.000us         0.01%       3.000us       1.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                             aten::set_         0.02%      11.000us         0.02%      11.000us       5.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                    aten::empty_strided         0.18%      89.000us         0.18%      89.000us      44.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                        cudaMemcpyAsync         4.31%       2.147ms         4.31%       2.147ms       1.073ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 49.817ms\n",
            "Self CUDA time total: 72.000us\n",
            "\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "ExhAdY9MAzuy",
        "outputId": "ca0c474f-ff8f-433d-f339-246cf485e20a"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "Parallelizing data loading has the potential to give massive speedups. As can be seen above, the running time decreases from over 5s with one dataloader to dozens of milliseconds with 2 loaders. The speedup continues with more dataloaders, until 8 loaders. When using 16 loaders, we instead see an increase in loading time. The system outputs a warning that this is above the recommended maximum, and this is where the communication overhead of the 16 processes becomes larger than the efficiency gain. Overall, we achieve a speedup greater than 300 for using 8 loaders over 1, although this is likely a fluke result as the system may need to warmup. Compared to 2 loaders, 8 loaders achieved a 2.6 time speedup, which is worse than linear but an important observation."
      ],
      "metadata": {
        "id": "yXBQS8vTA5iB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2KwbT_XCM3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}