{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling memory loading\n",
        "Another crucial part of training a deep learning model is the dataset, and of course loading the dataset from disk. This task can be parallelized, and we will now investigate how the number of CPU loaders affect the time."
      ],
      "metadata": {
        "id": "uDb9BLWu4uW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W73hMEoHNw_s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./data\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "itpSTtyAeR8B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(\n",
        "    root=path, train=True, download=True, transform=transform_train)"
      ],
      "metadata": {
        "id": "yxzlIGeEePat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2545e31-9380-41e9-ff3a-f574625694d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48075102.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset, num_workers, sort_string):\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    trainloader_enum = enumerate(trainloader)\n",
        "\n",
        "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "        with record_function(\"data_load\"):\n",
        "            batch_idx, (inputs, targets) = next(trainloader_enum)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)       \n",
        "\n",
        "    print(prof.key_averages().table(sort_by=sort_string, row_limit=15))"
      ],
      "metadata": {
        "id": "kk387JXbeNug"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Loader"
      ],
      "metadata": {
        "id": "yxwpniRs5qGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workers = 1\n",
        "sort_string = \"cuda_time_total\"\n",
        "load_data(trainset, workers, sort_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LPzBLow4n4_",
        "outputId": "8e3ebf5e-bea4-4979-f947-9c1a7d4e69f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                              data_load         1.34%       1.727ms       100.00%     129.146ms     129.146ms             1  \n",
            "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        98.57%     127.305ms        98.66%     127.418ms     127.418ms             1  \n",
            "                                            aten::empty         0.01%      16.000us         0.01%      16.000us       8.000us             2  \n",
            "                                               aten::to         0.01%       8.000us         0.01%       8.000us       2.000us             4  \n",
            "                                       aten::lift_fresh         0.00%       4.000us         0.00%       4.000us       2.000us             2  \n",
            "                                          aten::detach_         0.01%       8.000us         0.01%      12.000us       6.000us             2  \n",
            "                                                detach_         0.00%       4.000us         0.00%       4.000us       2.000us             2  \n",
            "                                             aten::set_         0.06%      74.000us         0.06%      74.000us      37.000us             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 129.146ms\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py:179: UserWarning: CUDA is not available, disabling CUDA profiling\n",
            "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrmOKBo-5zJZ"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}